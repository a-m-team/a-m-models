# <img src="assets/am_logo.png" style="vertical-align: middle; width: 35px;"> a-m-models [![Generic badge](https://img.shields.io/badge/ğŸ¤—-am%20team-green.svg)](https://huggingface.co/a-m-team)

*Read this in [English](README_en.md).*

a-m-models æ˜¯ç”± a-m-teams å‘èµ·çš„ä¸€ä¸ªå¼€æºé¡¹ç›®ï¼Œè‡´åŠ›äºå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä»¥åŠé€šç”¨äººå·¥æ™ºèƒ½ï¼ˆAGIï¼‰çš„å‰æ²¿æŠ€æœ¯è¿›è¡Œæ·±å…¥æ¢ç´¢ä¸å®è·µã€‚æˆ‘ä»¬çš„å›¢é˜Ÿç”±ä¸€ç¾¤å……æ»¡çƒ­æƒ…çš„ç ”ç©¶äººå‘˜å’Œå¼€å‘è€…ç»„æˆï¼Œèšç„¦äºå¤§æ¨¡å‹çš„ç†è®ºåˆ›æ–°ã€æ¶æ„è®¾è®¡ä»¥åŠå®æˆ˜åº”ç”¨ï¼Œæ—¨åœ¨é€æ­¥é€¼è¿‘é€šç”¨äººå·¥æ™ºèƒ½ï¼ˆAGIï¼‰çš„å®ç°ã€‚æœ¬é¡¹ç›®æ—¨åœ¨å¼€æºåˆ†äº«æˆ‘ä»¬åœ¨å¤§æ¨¡å‹é¢†åŸŸçš„æœ€æ–°ç ”ç©¶æˆæœä¸å®è·µç»éªŒï¼Œå¸Œæœ›èƒ½å¤Ÿæ¨åŠ¨ç¤¾åŒºå¯¹AGIæŠ€æœ¯çš„æ·±åº¦äº¤æµä¸å…±åŒè¿›æ­¥ã€‚

## ğŸ”„ æœ€è¿‘æ›´æ–°

* [2024-03-25] æ›´æ–°æŠ€æœ¯æŠ¥å‘Š[1.4 Million Open-Source Distilled Reasoning Dataset to Empower Large Language Model Traning](https://github.com/a-m-team/a-m-models/blob/main/docs/AM-DeepSeek-R1-Distilled-Dataset.pdf)ï¼Œå¼€æº140ä¸‡æ¡è’¸é¦æ¨ç†æ•°æ®ï¼Œå¤ç°DeepSeek-R1è’¸é¦æ¨¡å‹æ•ˆæœ

* [2024-03-25] æ›´æ–°æŠ€æœ¯æŠ¥å‘Š[Think Twice: Enhancing LLM Reasoning by Scaling Multi-round Test-time Thinking](https://github.com/a-m-team/a-m-models/blob/main/docs/Think-Twice.pdf)ï¼Œä»‹ç»äº†ä¸€ç§ç®€å•ä¸”æœ‰æ•ˆçš„æµ‹è¯•é˜¶æ®µæ‰©å±•æ–¹æ³•â€”â€”å¤šè½®æ€è€ƒï¼Œå…¶æ¨åŠ¨äº†SOTAæ¨¡å‹æ•ˆæœçš„è¿›ä¸€æ­¥æå‡

## ğŸ“‘ ç ”ç©¶æŠ¥å‘Š

### [Think Twice: Enhancing LLM Reasoning by Scaling Multi-round Test-time Thinking](https://github.com/a-m-team/a-m-models/blob/main/docs/Think-Twice.pdf)

è¿‘å¹´æ¥ï¼Œä»¥OpenAI-o1å’ŒDeepSeek-R1ä¸ºä»£è¡¨çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œè¿™äº›è¿›å±•è¡¨æ˜ï¼Œé€šè¿‡æµ‹è¯•é˜¶æ®µæ‰©å±•æ¨ç†æµç¨‹ï¼ˆtest-time scalingï¼‰ï¼Œå¯æ˜¾è‘—æå‡æ¨¡å‹è¡¨ç°ã€‚ç„¶è€Œï¼Œç›®å‰çš„æ¨¡å‹ä»å—åˆ°å¤„ç†é•¿æ–‡æœ¬èƒ½åŠ›å’Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è®­ç»ƒæ•ˆç‡çš„é™åˆ¶ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•ä¸”æœ‰æ•ˆçš„æµ‹è¯•é˜¶æ®µæ‰©å±•æ–¹æ³•â€”â€”å¤šè½®æ€è€ƒï¼ˆMulti-round Thinkingï¼‰ã€‚è¯¥æ–¹æ³•é€šè¿‡å°†æ¨¡å‹å…ˆå‰çš„å›ç­”ä½œä¸ºä¸‹ä¸€è½®æ¨ç†çš„æç¤ºï¼ˆpromptsï¼‰ï¼Œè¿­ä»£åœ°ç²¾è¿›æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ã€‚åœ¨åŒ…æ‹¬QwQ-32Bå’ŒDeepSeek-R1åœ¨å†…çš„å¤šä¸ªæ¨¡å‹ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œå¤šè½®æ€è€ƒèƒ½å¤Ÿåœ¨AIME 2024ã€MATH-500ã€GPQA-diamondå’ŒLiveCodeBenchç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ç¨³å®šæå‡æ¨¡å‹è¡¨ç°ã€‚ä¾‹å¦‚ï¼Œåœ¨AIME 2024æ•°æ®é›†ä¸­ï¼ŒQwQ-32Bçš„å‡†ç¡®ç‡ä»ç¬¬ä¸€è½®çš„80.3%æé«˜åˆ°ç¬¬äºŒè½®çš„82.1%ï¼ŒDeepSeek-R1ä¹Ÿè¡¨ç°å‡ºäº†ç±»ä¼¼çš„æå‡ï¼Œä»79.7%æé«˜åˆ°82.0%ã€‚è¿™äº›ç»“æœè¯æ˜ï¼Œå¤šè½®æ€è€ƒæ˜¯ä¸€ç§é€‚ç”¨å¹¿æ³›ã€å®æ–½ç®€å•ä¸”æœ‰æ•ˆæå‡æ¨¡å‹è¡¨ç°çš„æ–¹æ³•ï¼Œå½°æ˜¾å‡ºè¯¥æ–¹æ³•åœ¨æœªæ¥æµ‹è¯•é˜¶æ®µæ‰©å±•æŠ€æœ¯å‘å±•ä¸­çš„å·¨å¤§æ½œåŠ›ã€‚

The key prompt:
```
Original question prompt
The assistantâ€™s previous answer is: <answer> last round answer </answer>, and please re-answer.
```

![alt text](assets/Think-Twice-QwQ.png)
![alt text](assets/Think-Twice-DeepSeek-R1.png)

### [1.4 Million Open-Source Distilled Reasoning Dataset to Empower Large Language Model Traning](https://github.com/a-m-team/a-m-models/blob/main/docs/AM-DeepSeek-R1-Distilled-Dataset.pdf) [![Generic badge](https://img.shields.io/badge/ğŸ¤—-1.4M-green.svg)](https://huggingface.co/datasets/a-m-team/AM-DeepSeek-R1-Distilled-1.4M)

AM-DeepSeek-R1-Distilled æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡ã€å¸¦æœ‰æ¨ç†è¿‡ç¨‹çš„é€šç”¨æ¨ç†ä»»åŠ¡æ•°æ®é›†ï¼ŒåŒ…å«å¤§é‡é«˜è´¨é‡ä¸”å…·å¤‡æŒ‘æˆ˜æ€§çš„æ¨ç†é—®é¢˜ã€‚è¿™äº›é—®é¢˜æ”¶é›†è‡ªå¤šä¸ªå¼€æºæ•°æ®é›†ï¼Œç»è¿‡è¯­ä¹‰å»é‡å’Œç²¾ç»†æ¸…ç†ï¼Œä»¥æ¶ˆé™¤å¯èƒ½çš„æµ‹è¯•é›†æ±¡æŸ“é£é™©ã€‚æ•°æ®é›†ä¸­æ‰€æœ‰çš„ç­”æ¡ˆå‡ç”±æ¨ç†æ¨¡å‹ï¼ˆä¸»è¦ä¸º DeepSeek-R1ï¼‰è’¸é¦è€Œæˆï¼Œå¹¶ç»è¿‡ä¸¥æ ¼çš„éªŒè¯æµç¨‹ï¼šæ•°å­¦é—®é¢˜é€šè¿‡ä¸æ ‡å‡†ç­”æ¡ˆå¯¹æ¯”è¿›è¡ŒéªŒè¯ï¼Œä»£ç é—®é¢˜é€šè¿‡æµ‹è¯•ç”¨ä¾‹è¿›è¡Œæ ¸éªŒï¼Œè€Œå…¶ä»–ç±»å‹ä»»åŠ¡åˆ™é€šè¿‡å¥–åŠ±æ¨¡å‹è¿›è¡Œè¯„ä¼°ã€‚åŸºäºè¯¥æ•°æ®é›†ä»…ä½¿ç”¨ç®€å•ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰è®­ç»ƒçš„ AM-Distill-Qwen-32B æ¨¡å‹ï¼Œåœ¨ AIME2024ã€MATH-500ã€GPQA-Diamond ä»¥åŠ LiveCodeBench å››é¡¹åŸºå‡†æµ‹è¯•ä¸Šï¼Œå‡è¶…è¶Šäº†DeepSeek-R1-Distill-Qwen-32B æ¨¡å‹ã€‚ä¸ºäº†æ¨åŠ¨æ›´å¼ºå¤§çš„æ¨ç†å¯¼å‘å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å‘å±•ï¼Œæˆ‘ä»¬å¼€æºäº†è¿™140ä¸‡æ¡é—®é¢˜åŠå…¶å¯¹åº”çš„ç­”æ¡ˆã€‚è¯¥æ•°æ®é›†å·²å…¬å¼€åœ¨ <https://huggingface.co/datasets/a-m-team/AM-DeepSeek-R1-Distilled-1.4Mã€‚>

![alt text](assets/AM-DeepSeek-R1-Distilled.jpeg)

## Citation

å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„å·¥ä½œå¯¹æ‚¨çš„ç ”ç©¶æœ‰æ‰€å¸®åŠ©ï¼Œæ¬¢è¿ç»™æˆ‘ä»¬ç‚¹ä¸ªæ˜Ÿ :star:, å¹¶å¼•ç”¨æˆ‘ä»¬çš„å·¥ä½œ:pencil:

```BibTeX
@misc{AM-DeepSeek-R1-Distilled-1.4M,
      title={1.4 Million Open-Source Distilled Reasoning Dataset to Empower Large Language Model Traning}, 
      author={Han Zhao and Haotian Wang and Yiping Peng and Sitong Zhao and Xiaoyu Tian and Shuaiting Chen and Yunjie Ji and Xiangang Li},
      url = {https://github.com/a-m-team/a-m-models/blob/main/docs/AM-DeepSeek-R1-Distilled-Dataset.pdf},
      year={2025}
}

@misc{AM-DeepSeek-R1-Distilled-1.4M,
      title={AM DeepSeek R1 Distilled 1.4M}, 
      author={Han Zhao and Haotian Wang and Yiping Peng and Sitong Zhao and Xiaoyu Tian and Shuaiting Chen and Yunjie Ji and Xiangang Li},
      url = {https://github.com/a-m-team/a-m-models/blob/main/docs/AM-DeepSeek-R1-Distilled-Dataset.pdf},
      year={2025}
}


```
